#!/usr/bin/env python

"""
Filter top-50 follower countings
"""

import struct

from pydoop.mapreduce.pipes import run_task, Factory
from pydoop.mapreduce.api import Mapper, Reducer


class FilterMapper(Mapper):

    # def __init__(self, context):
    #     super(FilterMapper, self).__init__(context)
    #     jc = context.job_conf
    #     self.threshold = jc.get_int("filter.occurrence.threshold")

    def map(self, context):
        # Implements your codes
        print("DEBUG: mapper initiated")
        person, freq = context.key, context.value
        freq = struct.unpack(">i", freq)[0]

        print("DEBUG: struct unpacked")
        if freq >= 50:
            context.emit(str(person), str(freq))
        # Q. Why doesn't this work? its absoly same as the wordcount


class FilterReducer(Reducer):

    def reduce(self, context):
        # Implements your codes
        context.emit(context.key, context.value)
        # Q. Does it just pass?


if __name__ == "__main__":
    print("DEBUG: main_filter called")
    factory = Factory(FilterMapper, FilterReducer)
    run_task(factory)
